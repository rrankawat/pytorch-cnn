{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrankawat/pytorch-cnn/blob/main/CIFAR_10_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruning\n",
        "\n",
        "Pruning is a deep learning technique used to reduce a neural network's size by removing unnecessary components like weights, neurons, or entire layers, while aiming to maintain accuracy. This process makes models more efficient, requiring less computational power and memory, which is crucial for deployment on resource-constrained devices like smartphones and for real-time applications. Pruning can improve inference speed, lower energy consumption, and can also act as a form of regularization to help prevent overfitting.\n",
        "\n",
        "##### How it works\n",
        "\n",
        "* Identify and remove: The process involves identifying and removing redundant or less significant parameters. This is often done by assessing the importance of each weight, neuron, or filter.\n",
        "* Types of pruning:\n",
        "\n",
        "  *   Unstructured pruning: Removes individual weights, leading to sparse connections.\n",
        "  *   Structured pruning: Removes entire filters or neurons, which can be more efficient for hardware acceleration."
      ],
      "metadata": {
        "id": "0zLU76kcO4BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "yxsn47gmBQyB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZFF_AEM6rNw",
        "outputId": "cdd8cfae-47de-4e01-d042-7c5423d30fcb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVVVkcRswrab",
        "outputId": "a32c13b2-04f2-4baa-8bb0-3c57bb00710d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wildfire-detection.ipynb',\n",
              " '1. Getting Started.ipynb',\n",
              " '2. Grayscaling Images.ipynb',\n",
              " '3. Color Spaces.ipynb',\n",
              " '4. Drawing on Images.ipynb',\n",
              " 'Defect Analysis.ipynb',\n",
              " '01 Tensors.ipynb',\n",
              " '02 Tensor Operations.ipynb',\n",
              " '03 Tensor Math Operations.ipynb',\n",
              " '05 Convolutional Neural Network.ipynb',\n",
              " 'FashionMnist (1).ipynb',\n",
              " '04 Neural Network.ipynb',\n",
              " 'CIFAR-100.ipynb',\n",
              " 'Mnist.ipynb',\n",
              " 'model_fashion_mnist.pth',\n",
              " '__pycache__',\n",
              " 'model_fashion_mnist.py',\n",
              " 'FashionMnist.ipynb',\n",
              " 'model_cifar10.py',\n",
              " 'model_cifar10.pth',\n",
              " 'CIFAR-10.ipynb',\n",
              " 'CIFAR-10 Pruning.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def totalTime(start_time):\n",
        "  current_time = time.time()\n",
        "  total_time = (current_time - start_time) / 60\n",
        "  return round(total_time, 2)"
      ],
      "metadata": {
        "id": "QXteSloLNh-W"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)   # -> 16x32x32\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)  # -> 64x32x32\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) # -> 64x32x32\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1) # -> 128x32x32\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128*2*2, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)  # 32 -> 16\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)  # 16 -> 8\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)  # 8 -> 4\n",
        "\n",
        "        # Block 4\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)  # 4 -> 2\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, 128*2*2)\n",
        "\n",
        "        # Fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XetQb0DWjhp-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Load Model"
      ],
      "metadata": {
        "id": "7B_7g5h3fX20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "model = CIFARConvNet()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/model_cifar10.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN5SVTSbBZ6U",
        "outputId": "9ccf8f3e-197f-460c-e1db-7017a1a7f267"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CIFARConvNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Prepare Test Data"
      ],
      "metadata": {
        "id": "b16-Tda1fc1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "OPwHA-DKlh3i"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "ONKCAWiSlLgk"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Accuracy Function"
      ],
      "metadata": {
        "id": "vbydoj5afkAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_test, y_test in test_loader:\n",
        "            y_val = model(X_test)\n",
        "            predicted = torch.max(y_val.data, 1)[1]\n",
        "            total += y_test.size(0)\n",
        "            correct += (predicted == y_test).sum().item()\n",
        "    return correct / total * 100"
      ],
      "metadata": {
        "id": "qxLKGwmMl-F0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Prune the Model"
      ],
      "metadata": {
        "id": "XgeajFIOfoVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: prune 30% of weights in conv and fc layers\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        ")\n",
        "\n",
        "print(parameters_to_prune)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpNKnF0WmtRz",
        "outputId": "eaeb77d8-a4c6-4f31-fb6a-a600c6f3b74d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), 'weight'), (Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), 'weight'), (Linear(in_features=512, out_features=256, bias=True), 'weight'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer, param_name in parameters_to_prune:\n",
        "    print(layer, param_name)\n",
        "    prune.l1_unstructured(layer, name=param_name, amount=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx7HpfPNKQ_Y",
        "outputId": "b86c7454-631b-4fd8-e735-28f7d2de1064"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight\n",
            "Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) weight\n",
            "Linear(in_features=512, out_features=256, bias=True) weight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in model.named_modules():\n",
        "  if hasattr(module, 'weight_mask'):\n",
        "    sparsity = float(torch.sum(module.weight_mask == 0)) / float(module.weight_mask.nelement()) * 100\n",
        "    print(f\"Sparsity in {name}.weight: {sparsity:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN4zIrIYnWT5",
        "outputId": "b6eea0d4-bf94-404f-84b8-5b960ae04b54"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in conv1.weight: 30.09%\n",
            "Sparsity in conv2.weight: 29.99%\n",
            "Sparsity in fc1.weight: 30.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Test Accuracy After Pruning"
      ],
      "metadata": {
        "id": "my4b_3Kdf22W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_before = test_accuracy(model, test_loader)\n",
        "print(f\"Accuracy after pruning: {acc_before:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-lapnexoLsa",
        "outputId": "0a7e22ff-867c-4aa4-fbf8-16a2eeb265db"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after pruning: 70.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "PIx7LwVMNxre"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Fine-Tune"
      ],
      "metadata": {
        "id": "Mhm1TgyAf7I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# retrain for few epochs\n",
        "for epoch in range(2):  # small fine-tune\n",
        "    model.train()\n",
        "    for images, labels in test_loader:  # you can also use trainloader here\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f'Time taken: {totalTime(start_time)} minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRU9PyzeM9uP",
        "outputId": "7f13c24d-d477-46c8-f5e8-8076b86b958b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken: 0.54 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_after_ft = test_accuracy(model, test_loader)\n",
        "print(f\"Accuracy after fine-tuning: {acc_after_ft:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5opOEb5UNITA",
        "outputId": "824362b8-fc3c-4d1a-c835-d5c7928e30ec"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after fine-tuning: 89.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Make Pruning Permanent"
      ],
      "metadata": {
        "id": "RNrbAX1egHxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer, param_name in parameters_to_prune:\n",
        "    prune.remove(layer, param_name)"
      ],
      "metadata": {
        "id": "00WGhTiCOFsA"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Save the Pruned Model"
      ],
      "metadata": {
        "id": "2BC9tq_1gLvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/model_cifar10_pruned.pth\")\n",
        "print(\"✅ Model saved as model_cifar10_pruned.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVCJ4hfBOIZ5",
        "outputId": "7146b06e-bb6e-4e0f-af2a-2290a2a2f819"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved as model_cifar10_pruned.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/My Drive/Colab Notebooks/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGOcI2m4ObMd",
        "outputId": "25b286f1-cf1e-44af-92a7-c8c32fc28525"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wildfire-detection.ipynb',\n",
              " '1. Getting Started.ipynb',\n",
              " '2. Grayscaling Images.ipynb',\n",
              " '3. Color Spaces.ipynb',\n",
              " '4. Drawing on Images.ipynb',\n",
              " 'Defect Analysis.ipynb',\n",
              " '01 Tensors.ipynb',\n",
              " '02 Tensor Operations.ipynb',\n",
              " '03 Tensor Math Operations.ipynb',\n",
              " '05 Convolutional Neural Network.ipynb',\n",
              " 'FashionMnist (1).ipynb',\n",
              " '04 Neural Network.ipynb',\n",
              " 'CIFAR-100.ipynb',\n",
              " 'Mnist.ipynb',\n",
              " 'model_fashion_mnist.pth',\n",
              " '__pycache__',\n",
              " 'model_fashion_mnist.py',\n",
              " 'FashionMnist.ipynb',\n",
              " 'model_cifar10.py',\n",
              " 'model_cifar10.pth',\n",
              " 'CIFAR-10.ipynb',\n",
              " 'CIFAR-10 Pruning.ipynb',\n",
              " 'model_cifar10_pruned.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ldEs-0StQn451o39n_2SUvOJOoZiB-yX",
      "authorship_tag": "ABX9TyPQhomgeF9ORCC/CORkj92c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}